{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"main.jl\")\n",
    "using PyCall\n",
    "using CairoMakie\n",
    "sepsis_gym = pyimport(\"custom_sepsis\")\n",
    "using Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct MeansType\n",
    "    individual_runs::Vector{Vector{Float64}}\n",
    "    mean_rewards::Vector{Float64}\n",
    "    smoothed_mean::Vector{Float64}\n",
    "    smoothed_std::Vector{Float64}\n",
    "    keys_of_smoothed::Vector{Float64}\n",
    "end\n",
    "function calculate_mean_rewards(results, window_size)\n",
    "    rews = Dict()\n",
    "    means = Dict()\n",
    "    for (type, run) in results\n",
    "        all_keys = [sort(collect(keys(model.mean_rewards))) for model in run]\n",
    "        min_keys = minimum(length.(all_keys))\n",
    "        ks = all_keys[1][1:min_keys]\n",
    "        filled_rewards = []\n",
    "        all_rewards = []\n",
    "        rews = []\n",
    "        for model in run\n",
    "            rewards = [model.mean_rewards[1]]\n",
    "            for i in 2:min_keys\n",
    "                key = all_keys[1][i]\n",
    "                mult_factor = key - all_keys[1][i-1]\n",
    "                push!(rewards, fill(model.mean_rewards[key], mult_factor)...)\n",
    "            end\n",
    "            push!(all_rewards, [model.mean_rewards[k] for k in ks])\n",
    "            push!(filled_rewards, rewards)\n",
    "            push!(rews, rewards)\n",
    "        end\n",
    "        mean_rewards = mean(all_rewards)\n",
    "        std_rewards = std(all_rewards)\n",
    "        means[type] = MeansType( rews,  mean(filled_rewards),  moving_avg(mean_rewards, window_size),  Float64.(moving_avg(std_rewards, window_size)),  Float64.(ks))\n",
    "    end\n",
    "    return means\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Dict(\n",
    "    :Simple100 => [sepsis_gym.DirThompsonSampling.load_json(\"json/dirichlet/ts/Simple-$i.json\") for i in 0:2],\n",
    "    :Medium100 => [sepsis_gym.DirThompsonSampling.load_json(\"json/dirichlet/ts/Medium-$i.json\") for i in 0:2],\n",
    "    :None100 => [sepsis_gym.DirThompsonSampling.load_json(\"json/dirichlet/ts/None-$i.json\") for i in 0:2],\n",
    "    :Softmax100 => [load_jld(\"data/mcmc/runs/SoftmaxPPL-$i.jld\")  for i in 1:3],\n",
    "    :SimplePPL100 => [load_jld(\"data/mcmc/runs/SimplePPL-$i.jld\")  for i in 1:3],\n",
    "    :Simple1 => [sepsis_gym.DirThompsonSampling.load_json(\"json/dirichlet/ts/Simple-every-$i.json\") for i in 1:3],\n",
    "    :Medium1 => [sepsis_gym.DirThompsonSampling.load_json(\"json/dirichlet/ts/Medium-every-$i.json\") for i in 1:3],\n",
    "    :Softmax1 => [load_jld(\"data/mcmc/runs/SoftmaxPPL-every-$i.jld\")  for i in 1:3],\n",
    "    :SimplePPL1 => [load_jld(\"data/mcmc/runs/SimplePPL-every-$i.jld\")  for i in 1:3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = calculate_mean_rewards(ts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "struct MeanRewardsType\n",
    "    mean_rewards::Vector{Float64}\n",
    "    individual_runs::Vector{Vector{Float64}}\n",
    "    smoothed_mean::Vector{Float64}\n",
    "    smoothed_std::Vector{Float64}\n",
    "    name::String\n",
    "    info::Dict\n",
    "end\n",
    "function load_rewards_from_json(file_path)\n",
    "    json_data = JSON3.read(file_path)\n",
    "    mean_rewards = [Float64(rew) for rew in json_data[\"mean_rewards\"]]\n",
    "    individual_runs = [[Float64(rew) for rew in r] for r in json_data[\"individual_runs\"]]\n",
    "    smoothed_mean = [Float64(rew) for rew in json_data[\"smoothed_mean\"]]\n",
    "    smoothed_std = [Float64(rew) for rew in json_data[\"smoothed_std\"]]\n",
    "    name = json_data[\"name\"]\n",
    "    info = Dict(\n",
    "        string(k) => string(v) for (k, v) in json_data[\"info\"]\n",
    "    )\n",
    "    return MeanRewardsType(mean_rewards, individual_runs, smoothed_mean, smoothed_std, name, info)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = Dict(\n",
    "    :Simple100 => means[:Simple100],\n",
    "    :Medium100 => means[:Medium100],\n",
    "    :None100 => means[:None100],\n",
    "    :Softmax100 => means[:Softmax100],\n",
    "    :SimplePPL100 => means[:SimplePPL100],\n",
    "    :Simple1 => means[:Simple1],\n",
    "    :Medium1 => means[:Medium1],\n",
    "    :Softmax1 => means[:Softmax1],\n",
    "    :SimplePPL1 => means[:SimplePPL1],\n",
    "    :DQN_SE => load_rewards_from_json(\"json/dqn/sample_eff.json\"),\n",
    "    # :DQN_AR => load_rewards_from_json(\"json/dqn/asympt_results.json\"),\n",
    "    # :DQN_CR => load_rewards_from_json(\"json/dqn/cumul_results.json\"),\n",
    "    :QLearning => load_rewards_from_json(\"json/qlearning/q_learning_results.json\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_mean_rewards(means, batch_size, types, x_lim=15000)\n",
    "    fig = Figure(resolution=(900, 500))  \n",
    "    ax = Axis(fig[1, 1], xlabel = \"Number of Episodes\", ylabel = \"Mean Reward Across 100'000 Episodes\", title = \"Mean Rewards for Thompson Sampling with Batch Size $batch_size\")\n",
    "\n",
    "    ts_types = [:Simple100, :Medium100, :None100, :Softmax100, :SimplePPL100, :Simple1, :Medium1, :Softmax1, :SimplePPL1]\n",
    "    mfrl_types = [:DQN_SE, :DQN_AR, :DQN_CR, :QLearning]\n",
    "    filtered_ts = filter(x -> x in types, ts_types)\n",
    "    filtered_mfrl = filter(x -> x in types, mfrl_types)\n",
    "    # Data storage for accessing smoothed values later\n",
    "\n",
    "    ks = []\n",
    "    for (i, type) in enumerate(filtered_ts)\n",
    "        for mean in means[type].individual_means\n",
    "            lines!(ax, mean, color=(colors_dict[type], 0.2))\n",
    "        end\n",
    "        ks = means[type].keys_of_smoothed\n",
    "        smoothed_mean_rewards = means[type].smoothed_mean\n",
    "        lines!(ax, ks, Float64.(smoothed_mean_rewards), color=colors_dict[type], linewidth=1.5, label=label_dict[type])\n",
    "        smoothed_std_rewards = means[type].smoothed_std\n",
    "        low = smoothed_mean_rewards .- smoothed_std_rewards\n",
    "        high = smoothed_mean_rewards .+ smoothed_std_rewards\n",
    "        band!(ax, ks, low, high, color=(colors_dict[type], 0.2))\n",
    "    end\n",
    "    len = x_lim \n",
    "\n",
    "    lines!(ax, 1:len, fill(random_mean, len), color=:black, linestyle=:dash, label=\"Random Policy\")\n",
    "    # axislegend(ax, position=(:right, :bottom))\n",
    "\n",
    "    if x_lim != nothing\n",
    "        xlims!(ax, 0, x_lim)\n",
    "    end\n",
    "\n",
    "    for type in filtered_mfrl\n",
    "        smoothed = moving_avg(means[type].mean_rewards, 100)\n",
    "        lines!(ax, 1:length(smoothed), smoothed, color=(colors_dict[type]),label=label_dict[type])\n",
    "    end\n",
    "    \n",
    "    Legend(fig[1, 2], ax, position = :right)\n",
    "    \n",
    "    ylims!(ax, -1, 0)\n",
    "    ax.yticks = -1:0.05:0\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_mean_rewards(means, 100, [:SimplePPL100, :Softmax100, :Simple100, :Medium100, :None100], 50000)\n",
    "save(\"plots/ts100DQN1M.png\", fig)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_labels = Dict(\n",
    "    :Softmax => \"\\$\\\\mathsf{SoftmaxPPL}\\$\",\n",
    "    :None => \"\\$\\\\mathsf{FullDBN}\\$\",\n",
    "    :Medium => \"\\$\\\\mathsf{MediumDBN}\\$\",\n",
    "    :DQN => \"\\$\\\\mathsf{DQN}\\$\",\n",
    "    :SmoothedDQN => \"\\$\\\\mathsf{DQN}\\$\",\n",
    "    :Simple => \"\\$\\\\mathsf{SimpleDBN}\\$\",\n",
    "    :SimplePPL => \"\\$\\\\mathsf{SimplePPL}\\$\",\n",
    "    :Softmax100 => \"\\$\\\\mathsf{SoftmaxPPL\\\\_100}\\$\",\n",
    "    :None100 => \"\\$\\\\mathsf{FullDBN\\\\_100}\\$\",\n",
    "    :Medium100 => \"\\$\\\\mathsf{MediumDBN\\\\_100}\\$\",\n",
    "    :SmoothedDQN100 => \"\\$\\\\mathsf{DQN\\\\_100}\\$\",\n",
    "    :Simple100 => \"\\$\\\\mathsf{SimpleDBN\\\\_100}\\$\",\n",
    "    :SimplePPL100 => \"\\$\\\\mathsf{SimplePPL\\\\_100}\\$\",\n",
    "    :Softmax1 => \"\\$\\\\mathsf{SoftmaxPPL\\\\_1}\\$\",\n",
    "    :Medium1 => \"\\$\\\\mathsf{MediumDBN\\\\_1}\\$\",\n",
    "    :SmoothedDQN1 => \"\\$\\\\mathsf{DQN\\\\_1}\\$\",\n",
    "    :Simple1 => \"\\$\\\\mathsf{SimpleDBN\\\\_1}\\$\",\n",
    "    :SimplePPL1 => \"\\$\\\\mathsf{SimplePPL\\\\_1}\\$\",\n",
    "    :DQN_SE => \"\\$\\\\mathsf{DQN\\\\_SE}\\$\",\n",
    "    :DQN_AR => \"\\$\\\\mathsf{DQN\\\\_AR}\\$\",\n",
    "    :DQN_CR => \"\\$\\\\mathsf{DQN\\\\_CR}\\$\",\n",
    "    :QLearning => \"\\$\\\\mathsf{QLearning}\\$\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_cumsums(means)\n",
    "    cumsums = Dict()\n",
    "    for (type, mean) in means\n",
    "        cumsums[type] = cumsum(mean.mean_rewards, dims=1)\n",
    "    end\n",
    "    return cumsums\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sample_efficiency(means, checkpoints=[-1:0.05:1])\n",
    "    sample_eff = Dict()\n",
    "    for (type, mean) in means\n",
    "        sample_eff[type] = Dict()\n",
    "        for checkpoint in checkpoints\n",
    "            index = findfirst(x -> x >= checkpoint, mean.mean_rewards)\n",
    "            sample_eff[type][checkpoint] = isnothing(index) ? NaN : index\n",
    "        end\n",
    "    end\n",
    "    return sample_eff  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_asymptotic_reward(means, checkpoints=[0.5,0.7,0.9,0.99])\n",
    "    asymptotic_rewards = Dict{Symbol, Float64}()\n",
    "    convergence_speeds = Dict{Symbol, Dict{Float64, Int}}()\n",
    "    lengths = Dict{Symbol, Int}()\n",
    "\n",
    "    for (type, m) in means\n",
    "        rewards = m.mean_rewards\n",
    "        # Store the length of the rewards array\n",
    "        lengths[type] = length(rewards)\n",
    "        last_n = Int(round(lengths[type] / 10))\n",
    "\n",
    "        # Asymptotic mean reward\n",
    "        if !isempty(rewards)\n",
    "            asymptotic_rewards[type] = mean(rewards[end-last_n:end])\n",
    "        else\n",
    "            asymptotic_rewards[type] = NaN\n",
    "        end\n",
    "\n",
    "        # Convergence speed for each checkpoint\n",
    "        convergence_speeds[type] = Dict()\n",
    "        for checkpoint in checkpoints\n",
    "            min_reward = -1\n",
    "            max_reward = maximum(rewards)\n",
    "            reward_range = max_reward - min_reward\n",
    "            threshold_value = min_reward + checkpoint * reward_range\n",
    "            index = findfirst(x -> x >= threshold_value, rewards)\n",
    "            if isnothing(index)\n",
    "                convergence_speeds[type][checkpoint] = NaN  # Indicate no convergence\n",
    "            else\n",
    "                convergence_speeds[type][checkpoint] = index\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return asymptotic_rewards, convergence_speeds, lengths\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_order = [[:None100, :Medium100, :Simple100,:SimplePPL100, :Softmax100,], [:Medium1, :Simple1, :SimplePPL1, :Softmax1], [:QLearning]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "\n",
    "# Helper function to format best/worst values across types with your adjustments\n",
    "function format_best_worst_across_types(values_matrix; is_higher_better=true)\n",
    "    rows, cols = size(values_matrix)\n",
    "    formatted_matrix = Array{String}(undef, rows, cols)  # Initialize a matrix to store formatted values\n",
    "\n",
    "    for col in 1:cols\n",
    "        column_values = values_matrix[:, col]\n",
    "        max_val = maximum(column_values[.!isnan.(column_values)])\n",
    "        min_val = minimum(column_values[.!isnan.(column_values)])\n",
    "        for row in 1:rows\n",
    "            v = column_values[row]\n",
    "            if isnan(v)\n",
    "                formatted_matrix[row, col] = \"-\"\n",
    "            else\n",
    "                formatted_value = v\n",
    "                if v isa AbstractFloat\n",
    "                    formatted_value = round(v, digits=3)\n",
    "                end\n",
    "                if v == max_val && is_higher_better\n",
    "                    formatted_matrix[row, col] = \"\\\\color{blue}{\\$$(formatted_value)\\$}\"\n",
    "                elseif v == min_val && !is_higher_better\n",
    "                    formatted_matrix[row, col] = \"\\\\color{blue}{\\$$(formatted_value)\\$}\"\n",
    "                elseif v == min_val && is_higher_better\n",
    "                    formatted_matrix[row, col] = \"\\\\color{red}{\\$$(formatted_value)\\$}\"\n",
    "                elseif v == max_val && !is_higher_better\n",
    "                    formatted_matrix[row, col] = \"\\\\color{red}{\\$$(formatted_value)\\$}\"\n",
    "                else\n",
    "                    formatted_matrix[row, col] = \"\\$$(formatted_value)\\$\"\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return formatted_matrix\n",
    "end\n",
    "\n",
    "# Generate LaTeX table for cumulative rewards\n",
    "function generate_cumulative_rewards_table(cumsums, checkpoints)\n",
    "    types = collect(keys(cumsums))\n",
    "    cols = length(checkpoints)\n",
    "    \n",
    "    # Collect rewards for each type at each checkpoint into a matrix\n",
    "    values_matrix = [length(cumsums[type]) >= chk ? cumsums[type][chk-1] : NaN for type in types, chk in checkpoints]\n",
    "\n",
    "    # Format the values with best/worst highlighting\n",
    "    formatted_matrix = format_best_worst_across_types(values_matrix, is_higher_better=true)\n",
    "\n",
    "    # Create LaTeX table\n",
    "    header = \"\\\\hline\\n & \\$\" * join(checkpoints, \"\\$ & \\$\") * \"\\$ \\\\\\\\\\n\\\\hline\\n\"\n",
    "    rows = Dict()\n",
    "    for (i, type) in enumerate(types)\n",
    "        rows[type] = \"$(latex_labels[type]) & \" * join(formatted_matrix[i, :], \" & \") * \" \\\\\\\\\\n\"\n",
    "    end\n",
    "    rows_text = \"\"\n",
    "    for ts in type_order\n",
    "        for type in ts\n",
    "            rows_text *= rows[type]\n",
    "        end\n",
    "        rows_text *= \"\\\\hline\\n\"\n",
    "    end\n",
    "    return \"\\\\begin{tabular}{|l|\" * \"r\"^cols * \"|}\\n\\\\hline\\n\" * header * rows_text * \"\\\\hline\\n\\\\end{tabular}\"\n",
    "end\n",
    "\n",
    "# Generate LaTeX table for sample efficiency\n",
    "function generate_sample_efficiency_table(sample_eff, checkpoints, lengths)\n",
    "    types = collect(keys(sample_eff))\n",
    "    cols = length(checkpoints)\n",
    "    \n",
    "    # Collect sample efficiencies into a matrix\n",
    "    values_matrix = [sample_eff[type][chk] for type in types, chk in checkpoints]\n",
    "\n",
    "    # Format the values with best/worst highlighting\n",
    "    formatted_matrix = format_best_worst_across_types(values_matrix, is_higher_better=false)\n",
    "\n",
    "    # Create LaTeX table\n",
    "    header = \"\\\\hline\\n & \\$\" * join(checkpoints, \"\\$ & \\$\") * \"\\$ & Length \\\\\\\\\\n\\\\hline\\n\"\n",
    "    rows = Dict()\n",
    "    for (i, type) in enumerate(types)\n",
    "        rows[type] = \"$(latex_labels[type]) & \" * join(formatted_matrix[i, :], \" & \") * \" & \\$$(lengths[type])\\$ \\\\\\\\\\n\"\n",
    "    end\n",
    "\n",
    "    rows_text = \"\"\n",
    "    for ts in type_order\n",
    "        for type in ts\n",
    "            rows_text *= rows[type]\n",
    "        end\n",
    "        rows_text *= \"\\\\hline\\n\"\n",
    "    end\n",
    "    return \"\\\\begin{tabular}{|l|\" * \"r\"^cols * \"|r|}\\n\\\\hline\\n\" * header * rows_text * \"\\\\hline\\n\\\\end{tabular}\"\n",
    "end\n",
    "\n",
    "# Generate LaTeX table for asymptotic rewards\n",
    "function generate_asymptotic_rewards_table(asymptotic_rewards, convergence_speeds, checkpoints, lengths)\n",
    "    types = collect(keys(asymptotic_rewards))\n",
    "    cols = length(checkpoints)\n",
    "    \n",
    "    # Collect convergence speeds into a matrix\n",
    "    conv_matrix = [convergence_speeds[type][chk] for type in types, chk in checkpoints]\n",
    "    asym_matrix = [asymptotic_rewards[type] for type in types, chk in [1]]\n",
    "\n",
    "    # Format the values with best/worst highlighting\n",
    "    formatted_conv = format_best_worst_across_types(conv_matrix, is_higher_better=false)\n",
    "    formatted_asym = format_best_worst_across_types(asym_matrix, is_higher_better=true)\n",
    "    percentages = [\"\\$$(Int(chk*100))\\\\%\\$\" for chk in checkpoints]\n",
    "    # Create LaTeX table\n",
    "    header = \"\\\\hline\\n & Asymptotic Reward & \" * join(percentages, \" & \") * \" & Length \\\\\\\\\\n\\\\hline\\n\"\n",
    "    rows = Dict()\n",
    "    for (i, type) in enumerate(types)\n",
    "        rows[type] = \"$(latex_labels[type]) & {$(formatted_asym[i,1])} & \" * \n",
    "                     join(formatted_conv[i, :], \" & \") * \" & \\$$(lengths[type])\\$ \\\\\\\\\\n\"\n",
    "    end\n",
    "    rows_text = \"\"\n",
    "    for ts in type_order\n",
    "        for type in ts\n",
    "            rows_text *= rows[type]\n",
    "        end\n",
    "        rows_text *= \"\\\\hline\\n\"\n",
    "    end\n",
    "    return \"\\\\begin{tabular}{|l|r|\" * \"r\"^cols * \"|r|}\\n\\\\hline\\n\" * header * rows_text * \"\\\\hline\\n\\\\end{tabular}\"\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsums = get_cumsums(rewards)\n",
    "sample_eff = get_sample_efficiency(rewards, [-0.6,-0.5,-0.4,-0.3,-0.2,-0.1])\n",
    "asymptotic_rewards, convergence_speeds, lengths = get_asymptotic_reward(rewards, [0.6,0.7,0.8,0.9,0.99])\n",
    "\n",
    "\n",
    "# Generate tables\n",
    "cumulative_table = generate_cumulative_rewards_table(cumsums, [10,100,150,400,1000,3000])\n",
    "sample_eff_table = generate_sample_efficiency_table(sample_eff, [-0.6,-0.5,-0.4,-0.3,-0.2,-0.1], lengths)\n",
    "asymptotic_table = generate_asymptotic_rewards_table(asymptotic_rewards, convergence_speeds, [0.6,0.7,0.8,0.9,0.99], lengths)\n",
    "\n",
    "# Print LaTeX tables\n",
    "println(cumulative_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "println(sample_eff_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "println(asymptotic_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
